{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 990,
     "status": "error",
     "timestamp": 1605864750310,
     "user": {
      "displayName": "박인화20181377",
      "photoUrl": "",
      "userId": "16980852671291606978"
     },
     "user_tz": -540
    },
    "id": "NFW7Pd7_kasT",
    "outputId": "addfcf74-3ccb-4fa6-91c9-10baf85bc733"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fb2fc384cc96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m x_train = torch.FloatTensor([[73, 80, 75],\n\u001b[0;32m      5\u001b[0m                             \u001b[1;33m[\u001b[0m\u001b[1;36m93\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m93\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "w = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b # H(x) 계산\n",
    "\n",
    "# Hypothesis Function: Matrix\n",
    "hypothesis = x_train.matmul(w) + b\n",
    "\n",
    "# Cost\n",
    "cost = torch.mean((hypothesis - y_train)**2)\n",
    "\n",
    "#Gradient Desent\n",
    "optimizer = optim.SDG([w, b], lr=1e-5)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1605863772687,
     "user": {
      "displayName": "박인화20181377",
      "photoUrl": "",
      "userId": "16980852671291606978"
     },
     "user_tz": -540
    },
    "id": "g0THqtiQnKSM",
    "outputId": "8b75f09e-9663-441e-cb55-a2a767671b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    2/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    3/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    4/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    5/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    6/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    7/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    8/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    9/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   10/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   11/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   12/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   13/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   14/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   15/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   16/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   17/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   18/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   19/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch   20/20 hyporhesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "  hypothesis = x_train.matmul(w)+b\n",
    "  \n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "  # optimizer = optim.SDG([w, b], lr=1e-5)\n",
    "\n",
    "  # optimizer.zero_grad()\n",
    "  # cost.backward()\n",
    "  # optimizer.step()\n",
    "\n",
    "  print('Epoch {:4d}/{} hyporhesis: {} Cost: {:.6f}'.format(\n",
    "      epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1605863720758,
     "user": {
      "displayName": "박인화20181377",
      "photoUrl": "",
      "userId": "16980852671291606978"
     },
     "user_tz": -540
    },
    "id": "Gtxw9eNNyc78"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "  def __init__(self):\n",
    "     super().__init__()\n",
    "     self.linear = nn.Linear(3, 1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      return self.linear(x)\n",
    "  \n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "hypothesis = model(x_train)\n",
    "\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# cost = F.mse_loss(prediction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1605864646700,
     "user": {
      "displayName": "박인화20181377",
      "photoUrl": "",
      "userId": "16980852671291606978"
     },
     "user_tz": -540
    },
    "id": "oksIsPiUyuBW"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset      #torch.util.data 상속\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self):\n",
    "     self.x_data = [[73, 80, 75],\n",
    "                    [93, 88, 93],\n",
    "                    [89, 91, 90],\n",
    "                    [96, 98, 100],\n",
    "                    [73, 66, 70]]\n",
    "     self.y_data =  [[152], [185], [180], [196], [142]]\n",
    "\n",
    "# 이 데이터셋의 총 데이터 수\n",
    "  def __len__(self):\n",
    "      return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):   # 어떠한 인덱스 idx를 받았을 때, 그에 상응하는 입출력 데이터 반환\n",
    "      x = torch.FloatTensor(self.x_data[idx])\n",
    "      y = torch.FloatTensor(self.y_data[idx])\n",
    "\n",
    "      return x, y\n",
    "\n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1605864651074,
     "user": {
      "displayName": "박인화20181377",
      "photoUrl": "",
      "userId": "16980852671291606978"
     },
     "user_tz": -540
    },
    "id": "zG5jLc4Y9V6O"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 2,                 #각 minibatch의 크기\n",
    "    shuffle=True,                   #epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꾼다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 927,
     "status": "error",
     "timestamp": 1605864707391,
     "user": {
      "displayName": "박인화20181377",
      "photoUrl": "",
      "userId": "16980852671291606978"
     },
     "user_tz": -540
    },
    "id": "GdaN1sqR-UHw",
    "outputId": "b266ab60-c5af-41ce-c43f-b314a2094d16"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8ca5ece0e02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    x_train, y_train = samples\n",
    "\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer = optim.SDG([w, b], lr=1e-5)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hyporhesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWe4WmUM_gPM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdYJQQ6lWK15HLyBZJVAOH",
   "name": "Multivariable Linear regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
