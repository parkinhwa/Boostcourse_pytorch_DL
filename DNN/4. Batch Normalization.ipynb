{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Batch Normalization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNkrp5kBg4Sf+NfNNdCnxL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"dIUJB7ooytK9","executionInfo":{"status":"ok","timestamp":1606552439632,"user_tz":-540,"elapsed":744,"user":{"displayName":"박인화20181377","photoUrl":"","userId":"16980852671291606978"}}},"source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import random\n","# .to(device) : GPU를 사용하게 하는 코드 \n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1U0DVfxJy6ca","executionInfo":{"status":"ok","timestamp":1606553285418,"user_tz":-540,"elapsed":108723,"user":{"displayName":"박인화20181377","photoUrl":"","userId":"16980852671291606978"}},"outputId":"fd49a183-6268-447f-e929-74c371f65938"},"source":["# for reproducibility\n","random.seed(777)\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","    \n","# parameters\n","learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","\n","# MNIST dataset\n","mnist_train = dsets.MNIST(root='MNIST_data/',\n","                          train=True,\n","                          transform=transforms.ToTensor(),\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/',\n","                         train=False,\n","                         transform=transforms.ToTensor(),\n","                         download=True)\n","                         \n","# dataset loader\n","data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)\n","                                          \n","\n","test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          drop_last=True)\n","                                    \n","# nn layers\n","linear1 = torch.nn.Linear(784, 32, bias=True)\n","linear2 = torch.nn.Linear(32, 32, bias=True)\n","linear3 = torch.nn.Linear(32, 10, bias=True)\n","relu = torch.nn.ReLU()\n","bn1 = torch.nn.BatchNorm1d(32)\n","bn2 = torch.nn.BatchNorm1d(32)\n","nn_linear1 = torch.nn.Linear(784, 32, bias=True)\n","nn_linear2 = torch.nn.Linear(32, 32, bias=True)\n","nn_linear3 = torch.nn.Linear(32, 10, bias=True)\n","\n","# model\n","bn_model = torch.nn.Sequential(linear1, bn1, relu,\n"," linear2, bn2, relu,\n"," linear3).to(device)\n","\n","nn_model = torch.nn.Sequential(nn_linear1, relu,\n"," nn_linear2, relu,\n"," nn_linear3).to(device)\n","\n","# define cost/loss & optimizer\n","criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n","bn_optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)\n","nn_optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)\n","\n","train_losses = []\n","train_accs = []\n","\n","valid_losses = []\n","valid_accs = []\n","\n","train_total_batch = len(data_loader)\n","test_total_batch = len(test_loader)\n","\n","for epoch in range(training_epochs):\n","    bn_model.train() # set the model to train mode\n","    for X, Y in data_loader:\n","        # reshape input image into [batch_size by 784]\n","        # label is not one-hot encoded\n","        X = X.view(-1, 28 * 28).to(device)\n","        Y = Y.to(device)\n","\n","        bn_optimizer.zero_grad()\n","        bn_prediction = bn_model(X)\n","        bn_loss = criterion(bn_prediction, Y)\n","        bn_loss.backward()\n","        bn_optimizer.step()\n","\n","        nn_optimizer.zero_grad()\n","        nn_prediction = nn_model(X)\n","        nn_loss = criterion(nn_prediction, Y)\n","        nn_loss.backward()\n","        nn_optimizer.step()\n","\n","with torch.no_grad():\n","        bn_model.eval()     # set the model to evaluation mode\n","\n","        # Test the model using train sets\n","        bn_loss, nn_loss, bn_acc, nn_acc = 0, 0, 0, 0\n","        for i, (X, Y) in enumerate(data_loader):\n","            X = X.view(-1, 28 * 28).to(device)\n","            Y = Y.to(device)\n","\n","            bn_prediction = bn_model(X)\n","            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\n","            bn_loss += criterion(bn_prediction, Y)\n","            bn_acc += bn_correct_prediction.float().mean()\n","\n","        bn_loss,  bn_acc, = bn_loss / train_total_batch, bn_acc / train_total_batch\n","        bn_loss, bn_acc  = 0, 0\n","        for i, (X, Y) in enumerate(test_loader):\n","            X = X.view(-1, 28 * 28).to(device)\n","            Y = Y.to(device)\n","\n","            bn_prediction = bn_model(X)\n","            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\n","            bn_loss += criterion(bn_prediction, Y)\n","            bn_acc += bn_correct_prediction.float().mean()\n","\n","        bn_loss,  bn_acc = bn_loss / test_total_batch, bn_acc / test_total_batch\n","print('Learning finished')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Learning finished\n"],"name":"stdout"}]}]}
